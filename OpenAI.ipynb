{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Kerala is Thiruvananthapuram.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "name = llm.invoke(\"What is the capital of Kerala ?\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Thai Spice Kitchen\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "name = llm.invoke(\"Suggest a name for my Thai restaurant\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggest a name for my French restaurant\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = 'Suggest a name for my {cuisine} restaurant'\n",
    ")\n",
    "\n",
    "p = prompt_template_name.format(cuisine=\"French\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSuggest a name for my India restaurant\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/wfp348kn2dq3bn994w75sqrm0000gp/T/ipykernel_69115/2851112789.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt = prompt_template_name, verbose=True)\n",
      "/var/folders/8_/wfp348kn2dq3bn994w75sqrm0000gp/T/ipykernel_69115/2851112789.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"India\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Spice of India\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt = prompt_template_name, verbose=True)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = 'cuisine',\n",
    "    template = 'Suggest a name for my {cuisine} restaurant'\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt = prompt_template_name, verbose=True)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = 'Suggest some menu items for {restaurant_name}'\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSuggest a name for my American restaurant\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Fried Chicken and Waffles\n",
      "2. BBQ Pulled Pork Sliders\n",
      "3. Cajun Shrimp Po' Boy\n",
      "4. Philly Cheesesteak Sandwich\n",
      "5. New England Clam Chowder\n",
      "6. Tex-Mex Nachos\n",
      "7. Southern Style Biscuits and Gravy\n",
      "8. California Cobb Salad\n",
      "9. Chicago Deep Dish Pizza\n",
      "10. Hawaiian BBQ Chicken Skewers\n",
      "11. Louisiana Jambalaya\n",
      "12. New York Style Reuben Sandwich\n",
      "13. Texas Chili Cheese Fries\n",
      "14. Maryland Crab Cakes\n",
      "15. Vermont Maple Glazed Salmon.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain])\n",
    "\n",
    "content = chain.run(\"American\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = \"cuisine\",\n",
    "    template = \"Suggest a name for my {cuisine} restaurant\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt = prompt_template_name, output_key=\"restaurant_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = [\"restaurant_name\"],\n",
    "    template = \"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain, food_items_chain],\n",
    "    input_variables=['cuisine'],\n",
    "    output_variables=['restaurant_name', \"menu_items\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Italian',\n",
       " 'restaurant_name': '\\n\\n\"La Dolce Vita\" ',\n",
       " 'menu_items': '\\n\\n1. Antipasti platter with a selection of cured meats, cheeses, olives, and marinated vegetables\\n2. Caprese salad with fresh mozzarella, tomatoes, and basil\\n3. Spaghetti carbonara with pancetta, egg, and pecorino cheese\\n4. Chicken Marsala with a rich mushroom and Marsala wine sauce\\n5. Eggplant Parmesan served with a side of penne pasta\\n6. Seafood risotto with shrimp, scallops, and mussels\\n7. Grilled veal chop with a balsamic glaze and roasted vegetables\\n8. Margherita pizza topped with fresh tomatoes, mozzarella, and basil\\n9. Tiramisu, a classic Italian dessert made with ladyfingers, coffee, and mascarpone cheese\\n10. Gelato, a creamy and refreshing Italian ice cream, in various flavors such as pistachio, hazelnut, and strawberry.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"cuisine\": \"Italian\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
